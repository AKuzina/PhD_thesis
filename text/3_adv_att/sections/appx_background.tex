%-----SECTION-----

% \onecolumns
\newpage
\section{Background on MCMC}\label{appendix:background}

% ==== SubSECTION ====
\subsection{Sampling from an unnormalized density with MCMC}
Markov Chain Monte Carlo (MCMC) is a class of methods that are used to obtain samples from the density $p(\rvv)$ (also referred to as \textbf{target}), which is only known up to a normalizing constant. That is, we have access to $\tilde{p}(\rvv)$, such that $p(\rvv) = \frac{\tilde{p}(\rvv)}{Z}$ and $Z$ is a typically unknown and hard to estimate normalizing constant. Thus, we construct a Markov Chain with samples $\{\rvv^{(t)}\}_{t=1}^T$ so that they mimic the samples from $p(\rvv)$. To ensure they are proper samples, the stationary distribution of the constructed Markov Chain should be the target distribution $p(\rvv)$.

The most popular way of constructing such Markov Chains is the Metropolis-Hastings (MH) method. The majority of the MCMC methods used in practice can be formulated as a special case of the MH \cite{andrieu2003introduction}. In the MH method, we introduce a proposal distribution $q(\rvv^{t+1}|\rvv^t)$ to obtain a new sample and then accept it with the following probability:
\begin{equation}\label{eq:accept}
\mathcal{A}(\rvv^t, \rvv^{t+1})= \min\{ 1, \tfrac{p(\rvv^t)q(\rvv^{t+1}|\rvv^{t})}{p(\rvv^{t+1})q(\rvv^{t}|\rvv^{t+1})} \} .    
\end{equation}

If the point is not accepted, we reuse the previous point, i.e., $\rvv^{t+1} = \rvv^{t}$. It can be proven that the resulting chain of correlated samples converges in the distribution to the target density \cite{andrieu2003introduction}. 

It is worth mentioning that the performance of the method strongly depends on the choice of the proposal distribution. In higher dimensional spaces, it is especially important to incorporate the information about the geometry of the target distribution into the proposal density to improve the convergence time. The Hamiltonian Monte-Carlo (HMC) \cite{neal2011mcmc} is known to be one of the most efficient MCMC methods. It uses gradient of a target distribution in the proposal to incorporate the information about the geometry of the space.

The idea of the HMC is to introduce an auxiliary variable $\rvp$ with a known density (usually assumed to be the standard Gaussian) and the joint distribution formulated as follows: 

\begin{align}\label{eq:hmc}
p(\rvv, \rvp) &= \frac{1}{Z}\exp(-U(\rvv)) \exp(-K(\rvp)),   \\
\text{with:}& \notag\\
K(\rvp) &= - \frac{1}{2}\rvp^T\rvp, \\
U(\rvv) &= -\log \tilde{p}(\rvv). 
\end{align}

We obtain samples $(\rvv, \rvp)$ using the Hamiltonian dynamics \cite{neal2011mcmc} that describes how the $\rvv$ and $\rvp$ change over time for the given Hamiltonian $H(\rvv, \rvp) = U(\rvv) + K(\rvp)$, namely:

\begin{align}
\dot{\rvv} &= \frac{\partial H}{\partial \rvp},\\
\dot{\rvp} &= - \frac{\partial H}{\partial \rvv}.
\end{align}

For the practical implementation, these continuous-time equations are approximated by discretizing the time using $L$ small steps of size $\eta$. The discretization method that is often used is called the \textit{leapfrog}.

\subsection{The MCMC and Variational Autoencoders}
In this paper, we use the MCMC to sample from the posterior distribution $p_{\theta}(\rvz|\rvx^a)$. That is, in our case $\rvv = \rvz$ and $ \tilde{p}(\rvv) = p_{\theta}(\rvx^a|\rvz)p(\rvz)$. The HMC is a widely applied method to sampling from an unknown posterior distribution in deep learning (e.g. \cite{izmailov2021bayesian}). 
% and in VAEs specifically \cite{ruiz2019contrastive, salimans2015markov}. 
% This default implementation is only compatible with the continuous latent space.

A lot of effort was already done in combining variational inference with MCMC (and more specifically with HMC). Hamiltonian Variational Inference \cite{salimans2015markov, wolf2016variational} was proposed in order to obtain a more flexible variational approximation. Different approaches were proposed to use HMC during VAE training. \cite{hoffman2017learning} approximate the gradients of the likelihood and avoid the use of variational approximation. \cite{caterini2018hamiltonian} propose an unbiased estimate for the ELBO gradient, which allows training Hamiltonian Variational Autoencoder. \cite{ruiz2019contrastive} propose an alternative objective, which uses a contrastive divergence instead of standard KL-divergence. 

In this work we are not changing the training procedure, instead, we propose to only use HMC during evaluation. 
% way to approximate the 
% and Hamiltonian Variational Auto-Encoder  uses HMC to obtain a more flexible variational approximation. 

% MCMC was also widely applied to Variation In the context of VAEs, MCMC 

\paragraph{A possible extension to discrete latent spaces}
Some VAEs operate on discrete latent spaces, a very popular example would be a VQ-VAE \cite{van2017neural}. However, the classical HMC that we use in our experiments is not able to sample from a discrete distribution. Therefore, other MCMC methods should be used in this case, such as population-based MCMC \cite{auzina2021approximate}, modifications of HMC~\cite{nishimura2020discontinuous} or Langevin Dynamics~\cite{zhang2022langevin}.
% There are also modifications of the HMC that could deal with discrete random variables, e.g., \cite{nishimura2020discontinuous}.


% \subsection{Finding the mode of the posterior}

% We do not have a rigorous answer why HMC is definitely better, but intuitively we have the following motivation to use it instead of just maximizing the posterior:

% \paragraph{Posterior modes similarity}
% Ideally, we would like to obtain a sample from the variational posterior $q(z|x^r)$, due to its unavailability we sample from $p_{\theta}(z|x^a)$ instead. We show theoretically that the distance between these two distributions is bounded. However, that does guarantee that their modes are the same. Thus, the fact that the HMC allows us to “wander” around that mode may be beneficial. 

% \paragraph{Concentration of measure} During reconstruction, we get a sample from q and pass it to the decoder, thus, a mode can be actually a bad latent code for these purposes. Instead, ideally, we want to get a sample from the typical set where most of the probability mass is concentrated. In theory, the HMC allows us to do that. 


% \paragraph{Randomness} The HMC adds a source of randomness to our defence strategy that potentially makes it harder to attack. This is supported by our experiment in Section 4.3 (see the next question for the discussion).

\subsection{Mode optimization}\label{appendix:hmc_vs_opt}

In this work we hypothesise that adversarial attacks move latent codes to the region of low probability and we use HMC to get a sample from the high posterior probability region. However, another strategy can be to find the posterior mode instead. Here we explain, what was our motivation to not use this approach. 

\paragraph{Posterior modes similarity}
Ideally, we would like to obtain a sample from the variational posterior $q_{\phi}(\rvz|\rvx^r)$, because our decoder was trained to produce reconstructions from such latent codes. At the same time, VAE was trained to match this variational posterior to the true one $p_{\theta}(\rvz|\rvx^r)$. However, both these distributions are not available to us, since we observe attacked point $\rvx^a$ instead of the reference $\rvx^r$. 

Instead, we sample from $p_{\theta}(\rvz|\rvx^a)$ and show theoretically that the resulting samples are close (in terms of total variation distance) to the "goal" ones. However, that does guarantee that their modes are the same. Therefore, obtaining the mode of $p_{\theta}(\rvz|\rvx^a)$  is not necessarily a mode of $q_{\phi}(\rvz|\rvx^r)$. Thus, the fact that the HMC allows us to “wander” around that mode may be beneficial. 

\paragraph{Concentration of measure}
During reconstruction, we get a sample from $q(\rvz|\rvx)$ and pass it to the decoder, thus, a mode can actually be a bad latent code for these purposes. Instead, ideally, we want to get a sample from the typical set where most of the probability mass is concentrated. In theory, the HMC allows us to do that.

\paragraph{Randomness}
The HMC adds a source of randomness to our defence strategy that potentially makes it harder to attack. This is supported by our experiment in Section \ref{sec:ablation}
